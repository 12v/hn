{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreas.paxinos/Documents/github/mli/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "import tqdm\n",
    "import collections\n",
    "import more_itertools\n",
    "import requests\n",
    "import wandb\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "# r = requests.get(\"https://huggingface.co/datasets/ardMLX/text8/resolve/main/text8\")\n",
    "# with open(\"text8\", \"wb\") as f: f.write(r.content)\n",
    "with open('text8') as f: text8: str = f.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "16680599\n",
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "def preprocess(text: str) -> list[str]:\n",
    "  text = text.lower()\n",
    "  text = text.replace('.',  ' <PERIOD> ')\n",
    "  text = text.replace(',',  ' <COMMA> ')\n",
    "  text = text.replace('\"',  ' <QUOTATION_MARK> ')\n",
    "  text = text.replace(';',  ' <SEMICOLON> ')\n",
    "  text = text.replace('!',  ' <EXCLAMATION_MARK> ')\n",
    "  text = text.replace('?',  ' <QUESTION_MARK> ')\n",
    "  text = text.replace('(',  ' <LEFT_PAREN> ')\n",
    "  text = text.replace(')',  ' <RIGHT_PAREN> ')\n",
    "  text = text.replace('--', ' <HYPHENS> ')\n",
    "  text = text.replace('?',  ' <QUESTION_MARK> ')\n",
    "  text = text.replace(':',  ' <COLON> ')\n",
    "  words = text.split()\n",
    "  stats = collections.Counter(words)\n",
    "  words = [word for word in words if stats[word] > 5]\n",
    "  return words\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "corpus: list[str] = preprocess(text8)\n",
    "print(type(corpus)) # <class 'list'>\n",
    "print(len(corpus))  # 16,680,599\n",
    "print(corpus[:7])   # ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "16680599\n",
      "[5234, 3081, 12, 6, 195, 2, 3134]\n",
      "anarchism\n",
      "5234\n",
      "39\n",
      "63642\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "def create_lookup_tables(words: list[str]) -> tuple[dict[str, int], dict[int, str]]:\n",
    "  word_counts = collections.Counter(words)\n",
    "  vocab = sorted(word_counts, key=lambda k: word_counts.get(k), reverse=True)\n",
    "  int_to_vocab = {ii+1: word for ii, word in enumerate(vocab)}\n",
    "  int_to_vocab[0] = '<PAD>'\n",
    "  vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "  return vocab_to_int, int_to_vocab\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "words_to_ids, ids_to_words = create_lookup_tables(corpus)\n",
    "tokens = [words_to_ids[word] for word in corpus]\n",
    "print(type(tokens)) # <class 'list'>\n",
    "print(len(tokens))  # 16,680,599\n",
    "print(tokens[:7])   # [5234, 3081, 12, 6, 195, 2, 3134]\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "print(ids_to_words[5234])        # anarchism\n",
    "print(words_to_ids['anarchism']) # 5234\n",
    "print(words_to_ids['have'])      # 3081\n",
    "print(len(words_to_ids))         # 63,642\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1902"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_ids['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mFoo 8146176\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "class SkipGramFoo(torch.nn.Module):\n",
    "  def __init__(self, voc, emb, _):\n",
    "    super().__init__()\n",
    "    self.emb = torch.nn.Embedding(num_embeddings=voc, embedding_dim=emb)\n",
    "    self.ffw = torch.nn.Linear(in_features=emb, out_features=voc, bias=False)\n",
    "    self.sig = torch.nn.Sigmoid()\n",
    "\n",
    "  def forward(self, inpt, trgs, rand):\n",
    "    emb = self.emb(inpt)\n",
    "    ctx = self.ffw.weight[trgs]\n",
    "    rnd = self.ffw.weight[rand]\n",
    "    out = torch.bmm(ctx, emb.unsqueeze(-1)).squeeze()\n",
    "    rnd = torch.bmm(rnd, emb.unsqueeze(-1)).squeeze()\n",
    "    out = self.sig(out)\n",
    "    rnd = self.sig(rnd)\n",
    "    pst = -out.log().mean()\n",
    "    ngt = -(1 - rnd + 10**(-3)).log().mean()\n",
    "    return pst + ngt\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "embed_dim = 64\n",
    "initial_lr = 0.01\n",
    "arch = 'SkipGramFoo'\n",
    "args = (len(words_to_ids), embed_dim, 2)\n",
    "mFoo = SkipGramFoo(*args)\n",
    "print('mFoo', sum(p.numel() for p in mFoo.parameters()))\n",
    "opFoo = torch.optim.Adam(mFoo.parameters(), lr=initial_lr)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/andreas.paxinos/Documents/github/mli/material/hacker_news/wandb/run-20250130_171400-kwfv200g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andreasapaxinos-mli/mlx6-word2vec/runs/kwfv200g' target=\"_blank\">mFoo</a></strong> to <a href='https://wandb.ai/andreasapaxinos-mli/mlx6-word2vec' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andreasapaxinos-mli/mlx6-word2vec' target=\"_blank\">https://wandb.ai/andreasapaxinos-mli/mlx6-word2vec</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andreasapaxinos-mli/mlx6-word2vec/runs/kwfv200g' target=\"_blank\">https://wandb.ai/andreasapaxinos-mli/mlx6-word2vec/runs/kwfv200g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "epochs = 1\n",
    "windows = list(more_itertools.windowed(tokens, 3))\n",
    "inputs = [w[1] for w in windows]\n",
    "targets = [[w[0], w[2]] for w in windows]\n",
    "input_tensor = torch.LongTensor(inputs)\n",
    "target_tensor = torch.LongTensor(targets)\n",
    "dataset = torch.utils.data.TensorDataset(input_tensor, target_tensor)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "wandb.init(project='mlx6-word2vec'\n",
    "           ,config={\n",
    "        \"learning_rate\": initial_lr,\n",
    "        \"architecture\": arch,\n",
    "        \"dataset\": \"text8\",\n",
    "        \"epochs\": epochs,\n",
    "    }\n",
    "           , name='mFoo',)\n",
    "\n",
    "mFoo.to(device)\n",
    "for epoch in range(epochs):\n",
    "  prgs = tqdm.tqdm(dataloader, desc=f\"Epoch {epoch+1}\", leave=False)\n",
    "  for inpt, trgs in prgs:\n",
    "    inpt, trgs = inpt.to(device), trgs.to(device)\n",
    "    rand = torch.randint(0, len(words_to_ids), (inpt.size(0), 2)).to(device)\n",
    "    opFoo.zero_grad()\n",
    "    loss = mFoo(inpt, trgs, rand)\n",
    "    loss.backward()\n",
    "    opFoo.step()\n",
    "    wandb.log({'loss': loss.item()})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar words to 'cat' before training:\n",
      "cat: 122.651\n",
      "tricolour: 43.696\n",
      "offends: 40.661\n",
      "andromache: 40.570\n",
      "apparitions: 39.769\n",
      "conquered: 39.643\n",
      "rota: 39.596\n",
      "zweites: 39.500\n",
      "phocidae: 38.865\n",
      "konkan: 38.744\n",
      "\n",
      "Top similar words to 'cat' after training:\n",
      "cat: 122.651\n",
      "gassan: 43.696\n",
      "connor: 40.661\n",
      "alamos: 40.570\n",
      "seabird: 39.769\n",
      "happen: 39.643\n",
      "morden: 39.596\n",
      "medicis: 39.500\n",
      "rivaled: 38.865\n",
      "utter: 38.744\n"
     ]
    }
   ],
   "source": [
    "# check embedding before training\n",
    "word_of_interest = 'cat'\n",
    "\n",
    "# select word of interest\n",
    "word_id = words_to_ids[word_of_interest]\n",
    "start_embed = torch.nn.Embedding(len(words_to_ids), embedding_dim=embed_dim)\n",
    "word_embed = start_embed.weight.data[word_id]  # shape: [64]\n",
    "\n",
    "# Get all embeddings (vocab_size x 64)\n",
    "all_embeds = start_embed.weight.data  # shape: [vocab_size, 64]\n",
    "\n",
    "# Compute dot products (matrix multiplication)\n",
    "before_dot_products = torch.matmul(all_embeds, word_embed)  # shape: [vocab_size]\n",
    "\n",
    "# Get top 10 most similar words\n",
    "top_k = 10\n",
    "values, indices = torch.topk(before_dot_products, k=top_k)\n",
    "\n",
    "# Convert indices to words\n",
    "before_similar_words = [ids_to_words[idx.item()] for idx in indices]\n",
    "\n",
    "    \n",
    "# check embedding after training\n",
    "final_embeddings = mFoo.emb.weight.data  # Shape: [vocab_size, embedding_dim]\n",
    "final_word_embed = final_embeddings[word_id]  # shape: [64]\n",
    "\n",
    "# Compute dot products (matrix multiplication)\n",
    "after_dot_products = torch.matmul(final_embeddings, final_word_embed)  # shape: [vocab_size]\n",
    "\n",
    "# Get top 10 most similar words\n",
    "values, indices = torch.topk(after_dot_products, k=top_k)\n",
    "\n",
    "# Convert indices to words\n",
    "after_similar_words = [ids_to_words[idx.item()] for idx in indices]\n",
    "\n",
    "\n",
    "print(\"Top similar words to '\"+word_of_interest+\"' before training:\")\n",
    "for word, score in zip(before_similar_words, values):\n",
    "    print(f\"{word}: {score:.3f}\")\n",
    "print('')\n",
    "print(\"Top similar words to '\"+word_of_interest+\"' after training:\")\n",
    "for word, score in zip(after_similar_words, values):\n",
    "    print(f\"{word}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Uploading...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▄▃▃█▄▃▃▂▃▃▂▂▃▂▁▁▂▂▂▂▁▁▂▂▂▁▁▂▃▂▂▂▁▃▂▁▃▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.3621</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mFoo</strong> at: <a href='https://wandb.ai/andreasapaxinos-mli/mlx6-word2vec/runs/b7tdrvpr' target=\"_blank\">https://wandb.ai/andreasapaxinos-mli/mlx6-word2vec/runs/b7tdrvpr</a><br> View project at: <a href='https://wandb.ai/andreasapaxinos-mli/mlx6-word2vec' target=\"_blank\">https://wandb.ai/andreasapaxinos-mli/mlx6-word2vec</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250130_135407-b7tdrvpr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "print('Saving...')\n",
    "torch.save(mFoo.state_dict(), './weights.pt')\n",
    "print('Uploading...')\n",
    "artifact = wandb.Artifact('model-weights', type='model')\n",
    "artifact.add_file('./weights.pt')\n",
    "wandb.log_artifact(artifact)\n",
    "print('Done!')\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
