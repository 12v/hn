import os
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import numpy as np
import pandas as pd
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
from numpy import array

#Generating random data to test training
data = {
    "matrix": [np.random.rand(256, 1) for _ in range(10000)],
    "score": np.random.rand(10000),
    }
dataframe = pd.DataFrame(data)

class RandomDataset(Dataset):
    def __init__(self, dataframe):
        self.dataframe = dataframe

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        # Extract the matrix and score
        matrix = self.dataframe.iloc[idx]["matrix"]
        score = self.dataframe.iloc[idx]["score"]
        
        # Convert to PyTorch tensors
        matrix_tensor = torch.tensor(matrix, dtype=torch.float32).squeeze()  # Flatten to (256,)
        score_tensor = torch.tensor(score, dtype=torch.float32)
        
        return matrix_tensor, score_tensor

# Create Dataset
dataset = RandomDataset(dataframe)
#DODGY

# Defining DataLoader
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

class NeuralNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(p=0.1),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(p=0.1),
            nn.Linear(64, 1),
        )

    def forward(self, x):
        logits = self.linear_relu_stack(x)
        return logits
criterion = nn.MSELoss()

epoch_losses = []

model = NeuralNetwork()
optimiser = torch.optim.Adam(model.parameters(), lr=0.001)
epochs=20
for epoch in range(epochs):
    epoch_loss = 0.0
    for batch in dataloader:
        # Get the input matrix and target score
        inputs, targets = batch
        
        # Forward pass
        predictions = model(inputs)
        loss = criterion(predictions.squeeze(), targets)  # Squeeze to match dimensions
        
        # Backward pass and optimisation
        optimiser.zero_grad()
        loss.backward()
        optimiser.step()
        
        epoch_loss += loss.item()

    epoch_loss /= len(dataloader)
    epoch_losses.append(epoch_loss)




print(f"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}")

epoch_losses = [round(loss, 4) for loss in epoch_losses]
epoch_losses
